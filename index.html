<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="IDD3D: Indian Driving Dataset for 3D Unstructured Roads, Published at WACV 2023.">
  <meta property="og:title" content="IDD-3D"/>
  <meta property="og:description" content="IDD3D: Indian Driving Dataset for 3D Unstructured Roads, Published at WACV 2023."/>
  <meta property="og:url" content="idd3d.github.io"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <!-- <meta property="og:image" content="static/image/your_banner_image.png" /> -->
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>
  
  
  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <!-- <meta name="twitter:image" content="static/images/your_twitter_banner_image.png"> -->
  <!-- <meta name="twitter:card" content="summary_large_image"> -->
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="IDD IDD-3D">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  
  <title>IDD-3D: Indian Driving Dataset for 3D Unstructured Road Scenes</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">
  
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>
  
  
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">IDD-3D: Indian Driving Dataset for 3D Unstructured Road Scenes</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block"><a href="https://shubham1810.github.io/" target="_blank">Shubham Dokania</a><sup>1</sup>,</span>
              <span class="author-block"><a href="https://scholar.google.co.in/citations?user=81UGxdYAAAAJ&hl=en" target="_blank">A. H. Abdul Hafez</a><sup>2</sup>,</span>
              <span class="author-block"><a href="https://sites.google.com/view/anbumani/" target="_blank">Anbumani Subramaniam</a><sup>1</sup></span>
              <br>
              <span class="author-block"><a href="https://cseweb.ucsd.edu/~mkchandraker/" target="_blank">Manmohan Chandraker</a><sup>3</sup></span>
              <span class="author-block"><a href="https://faculty.iiit.ac.in/~jawahar/" target="_blank">C.V. Jawahar</a><sup>1</sup></span>
              </div>
              
              <div class="is-size-5 publication-authors">
                <span class="author-block"><sup>1</sup>IIIT Hyderabad, India, <sup>2</sup>Hasan Kalyoncu University, Turkey, <br><sup>3</sup> UC San Diego, USA<br>WACV 2023</span>
                <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
              </div>
              
              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- Arxiv PDF link -->
                  <span class="link-block">
                    <a href="https://openaccess.thecvf.com/content/WACV2023/papers/Dokania_IDD-3D_Indian_Driving_Dataset_for_3D_Unstructured_Road_Scenes_WACV_2023_paper.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>
                  
                  <!-- Supplementary PDF link -->
                  <span class="link-block">
                    <a href="static/pdfs/IDD3D_WACV_supplementary.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Supplementary</span>
                  </a>
                </span>
                
                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/shubham1810/idd3d_kit" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
              
              <!-- ArXiv abstract Link -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2210.12878" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>




<!-- Create section for Teaser Image and a caption -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-centered">
            <img src="static/images/teaser_image.png" alt="IDD-3D Teaser image" width="80%"/>
      <h2 class="subtitle has-text-centered">
        Some examples from the dataset showing different traffic
scenarios, LiDAR data with annotations, and a sample of LiDAR
point clouds projected on camera data
      </h2>
    </div>
  </div>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Autonomous driving and assistance systems rely on annotated data from traffic and road scenarios to model and learn the various object relations in complex real-world scenarios. Preparation and training of deploy-able deep learning architectures require the models to be suited to different traffic scenarios and adapt to different situations. Currently, existing datasets, while large-scale, lack such diversities and are geographically biased towards mainly developed cities. An unstructured and complex driving layout found in several developing countries such as India poses a challenge to these models due to the sheer degree of variations in the object types, densities, and locations. To facilitate better research toward accommodating such scenarios, we build a new dataset, {IDD-3D}, which consists of multi-modal data from multiple cameras and LiDAR sensors with 12k annotated driving LiDAR frames across various traffic scenarios. We discuss the need for this dataset through statistical comparisons with existing datasets and highlight benchmarks on standard 3D object detection and tracking tasks in complex layouts.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Make a section for a summary of IDD-3D -->
<section class="section hero is-dark">
  <div class="container is-max-desktop">
    <div class="columns ">
      <div class="column is-four-fifths">
        <h2 class="title is-3">IDD-3D Summary</h2>
        <div class="content has-text-justified">
          <p>
            IDD-3D is a groundbreaking dataset designed to address the challenges of autonomous driving in unstructured environments. While existing datasets have primarily focused on well-organized, controlled settings, IDD-3D takes a different approach by capturing the complexities of real-world driving scenarios. The dataset is particularly unique for its focus on diverse and chaotic driving conditions, often encountered in cities like Hyderabad, India.

            <h3 class="title is-4">Key Features:</h3>
              <ul>
                <li><strong>Diverse Geographical Coverage:</strong> IDD-3D is collected across various regions of Hyderabad, encompassing a range of road types, traffic densities, and environmental conditions.</li>
                <li><strong>Rich Annotations:</strong> The dataset includes 3D bounding box annotations for approximately 223k objects across 17 categories. This enables a wide array of applications, from object detection to tracking and beyond.</li>
                <li><strong>High-Quality Data:</strong> The dataset is meticulously curated, with high-resolution LiDAR and camera sensors capturing over 5 hours of driving data.</li>
                <li><strong>Unique Object Categories:</strong> Unlike other datasets that often generalize objects into broad categories, IDD-3D provides a more nuanced classification, including unique vehicle types and pedestrian behaviors commonly seen in unstructured environments.</li>
              </ul>

          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Some Interesting Cases</h2>
      <p>
        We highlight some interesting cases in the images below from the data collection and the traffic scenarios encountered and present in the dataset. The cases highlight different aspects of the dataset, the diversity available, and how the data can be used for different applications.
      </p>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item has-text-centered">
          <!-- Your image here -->
          <img src="static/images/interesting_01.png" alt="multiple directions"/>
          <h2 class="subtitle has-text-centered">
            A case with  different vehicle orientations and occlusions in the traffic scene. We can see the heading direction of the vehicles is distributed in multiple directions, rather than being aligned in a small range such as in the case of other datasets.
          </h2>
        </div>
        <div class="item has-text-centered">
          <!-- Your image here -->
          <img src="static/images/interesting_02.png" alt="road levels"/>
          <h2 class="subtitle has-text-centered">
            We highlight multiple levels of drivable surfaces including roads, highways, flyovers etc. The data collection vehicles were driven across different parts of the city to capture the diversity in the road layouts and different heights. It is important to note that the objects in the scene are annotated irrespective of their height as long as they are visible in the LiDAR data. This allows for better understanding of geometric layouyt of the traffic scenes.
          </h2>
        </div>
        <div class="item has-text-centered">
          <!-- Your image here -->
          <img src="static/images/interesting_03.png" alt="traffic safety"/>
          <h2 class="subtitle has-text-centered">
            This image shows an example of a traffic safety critical scenario where we can see pedestrians crossing the road in front of a vehicle. The dataset includes such scenarios which are important for developing safety critical systems. Analysis of objects in detection and tracking systems can lead to safer roads.
          </h2>
        </div>
        <div class="item has-text-centered">
          <!-- Your image here -->
          <img src="static/images/interesting_04.png" alt="high density"/>
          <h2 class="subtitle has-text-centered">
            We highlight high density traffic scenarios in the dataset with a higher number of objects based on distance thresholds compared to other popular datasets, especially in unstructured scenarios. The importance of using the LiDAR sensor especially is clear in this scenario where there exists heavy occlusion in the camera FoV due to the heavy traffic condition and the vehicles being in close proximity.
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End image carousel -->

<!-- Make a section for a summary of IDD-3D -->
<section class="section hero is-dark">
  <div class="container is-max-desktop">
    <div class="columns ">
      <div class="column is-four-fifths">
        <h2 class="title is-3">IDD-3D Summary</h2>
        <div class="content has-text-justified">            
            <h3 class="title is-4">Experimental Insights:</h3>
              <p>The paper presents a comprehensive analysis of the dataset using popular object detection methods like CenterPoint, SECOND, and PointPillars. The results validate the robustness and applicability of IDD-3D for developing more adaptive driving systems.</p>

              <p>IDD-3D also includes a 3D object tracking evaluation, offering valuable metrics that can be used to understand object motion and behavior in complex scenarios.</p>

              <h3 class="title is-4">Applications Beyond Autonomous Driving:</h3>
              <p>The dataset is not just limited to autonomous driving; its rich annotations and diverse scenarios make it applicable in other domains like road safety, traffic management, and surveillance.</p>

          </p>
        </div>
      </div>
    </div>
  </div>
</section>






<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>
      <iframe  src="static/pdfs/WACV23_IDD3D_Poster__Final_.pdf" width="100%" height="550">
      </iframe>
      
    </div>
  </div>
</section>
<!--End paper poster -->


<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
@InProceedings{Dokania_2023_WACV,
  author    = {Dokania, Shubham and Hafez, A. H. Abdul and Subramanian, Anbumani and Chandraker, Manmohan and Jawahar, C. V.},
  title     = {IDD-3D: Indian Driving Dataset for 3D Unstructured Road Scenes},
  booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
  month     = {January},
  year      = {2023},
  pages     = {4482-4491}
}
    </code></pre>
  </div>
</section>
<!--End BibTex citation -->


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-10">
        <div class="content">
          
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page. This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            
          </div>
        </div>
      </div>
    </div>
  </footer>
  
  <!-- Statcounter tracking code -->
  
  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->
  
  <!-- End of Statcounter Code -->
  
</body>
</html>
